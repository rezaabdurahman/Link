name: Frontend Tests

# Frontend unit and integration testing workflow
# Split from large frontend-ci.yml for better maintainability

on:
  push:
    branches: [main, develop]
    paths: 
      - 'frontend/**'
      - '.github/workflows/frontend-tests.yml'
  pull_request:
    branches: [main, develop]
    paths: 
      - 'frontend/**'
  workflow_call:
    outputs:
      test_status:
        description: 'Overall test status'
        value: ${{ jobs.test-summary.outputs.status }}

env:
  NODE_VERSION: '18'
  CACHE_VERSION: 'v2'
  FORCE_COLOR: 1

concurrency:
  group: frontend-tests-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ================================================================
  # UNIT & INTEGRATION TESTS
  # ================================================================
  
  unit-tests:
    name: ğŸ§ª Unit & Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4
        
      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'

      - name: ğŸ—‚ï¸ Cache dependencies and build artifacts
        uses: actions/cache@v4
        with:
          path: |
            frontend/node_modules/.cache
            frontend/coverage
          key: ${{ env.CACHE_VERSION }}-frontend-test-${{ runner.os }}-${{ hashFiles('frontend/package-lock.json') }}
          restore-keys: |
            ${{ env.CACHE_VERSION }}-frontend-test-${{ runner.os }}-
          
      - name: ğŸ”§ Install dependencies
        working-directory: frontend
        run: npm ci --prefer-offline --no-audit
        
      - name: ğŸ—ï¸ Setup test environment
        working-directory: frontend
        run: |
          # Create test environment file
          if [ ! -f .env.test ]; then
            cp .env.test.example .env.test 2>/dev/null || echo "NODE_ENV=test" > .env.test
          fi
          echo "Test environment configured"

      - name: ğŸ§ª Run unit tests with coverage
        working-directory: frontend
        run: |
          echo "Running unit tests..."
          npm run test:coverage:ci 2>&1 | tee test-results.txt
          
          if [ ${PIPESTATUS[0]} -ne 0 ]; then
            echo "âŒ Unit tests failed"
            exit 1
          fi
          
          echo "âœ… Unit tests passed"
        env:
          NODE_ENV: test
          CI: true

      - name: ğŸ“Š Generate coverage summary
        working-directory: frontend
        run: |
          if [ -f "coverage/lcov.info" ]; then
            echo "ğŸ“ˆ Coverage Summary:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            npm run test:coverage:summary 2>/dev/null || echo "Coverage summary not available" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: ğŸ“¤ Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: |
            frontend/coverage/
            frontend/test-results.txt
          retention-days: 7
          
      - name: ğŸ“Š Upload coverage to Codecov
        if: success()
        uses: codecov/codecov-action@v4
        with:
          files: ./frontend/coverage/lcov.info
          directory: ./frontend
          flags: frontend
          name: frontend-coverage
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # ================================================================
  # INTEGRATION TESTS (with mock services)
  # ================================================================
  
  integration-tests:
    name: ğŸ”— Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [unit-tests]
    
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4
        
      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'

      - name: ğŸ”§ Install dependencies
        working-directory: frontend
        run: npm ci --prefer-offline --no-audit
        
      - name: ğŸš€ Start mock services
        working-directory: frontend
        run: |
          # Start MSW (Mock Service Worker) if configured
          if npm list @mswjs/cli >/dev/null 2>&1; then
            echo "Starting Mock Service Worker..."
            npm run msw:start &
            MSW_PID=$!
            echo "MSW_PID=$MSW_PID" >> $GITHUB_ENV
            sleep 5
          else
            echo "No MSW configuration found, skipping mock services"
          fi

      - name: ğŸ”— Run integration tests
        working-directory: frontend
        run: |
          echo "Running integration tests..."
          
          if npm run test:integration >/dev/null 2>&1; then
            npm run test:integration
            echo "âœ… Integration tests passed"
          else
            echo "âš ï¸ No integration tests configured"
          fi
        env:
          NODE_ENV: test
          CI: true

      - name: ğŸ›‘ Stop mock services
        if: always()
        run: |
          if [ -n "${MSW_PID:-}" ]; then
            kill $MSW_PID || true
            echo "Mock services stopped"
          fi

  # ================================================================
  # TEST SUMMARY
  # ================================================================
  
  test-summary:
    name: ğŸ“‹ Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    if: always()
    outputs:
      status: ${{ steps.summary.outputs.status }}
    
    steps:
      - name: ğŸ“Š Generate test summary
        id: summary
        run: |
          echo "# ğŸ§ª Frontend Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check job results
          unit_result="${{ needs.unit-tests.result }}"
          integration_result="${{ needs.integration-tests.result }}"
          
          echo "## ğŸ“Š Results Overview" >> $GITHUB_STEP_SUMMARY
          echo "| Test Type | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | $unit_result |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | $integration_result |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Determine overall status
          if [[ "$unit_result" == "success" && "$integration_result" == "success" ]]; then
            echo "## âœ… Overall Status: SUCCESS" >> $GITHUB_STEP_SUMMARY
            echo "All frontend tests passed successfully!" >> $GITHUB_STEP_SUMMARY
            overall_status="success"
          else
            echo "## âŒ Overall Status: FAILURE" >> $GITHUB_STEP_SUMMARY
            echo "Some frontend tests failed. Please check the detailed results above." >> $GITHUB_STEP_SUMMARY
            overall_status="failure"
          fi
          
          echo "status=$overall_status" >> $GITHUB_OUTPUT
          
      - name: âŒ Fail if tests failed
        if: steps.summary.outputs.status == 'failure'
        run: |
          echo "Frontend tests failed"
          exit 1